{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05f7f100",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Dd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Dd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# set seed for reproducibility\n",
    "np.random.seed(493)\n",
    "\n",
    "import json \n",
    "import csv\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "ps = nltk.porter.PorterStemmer()\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "\n",
    "from gsdmm import MovieGroupProcess\n",
    "\n",
    "# set seed for reproducibility\n",
    "np.random.seed(493)\n",
    "\n",
    "# to print out all the outputs\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c8e467a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('../data/in/trump_archive.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a000aa71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>favorites</th>\n",
       "      <th>id</th>\n",
       "      <th>isRetweet</th>\n",
       "      <th>retweets</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-06 23:01:04</td>\n",
       "      <td>0</td>\n",
       "      <td>1346954970910707712</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>These are the things and events that happen when a sacred landslide election victory is so unceremoniously &amp;amp; viciously stripped away from great patriots who have been badly &amp;amp; unfairly treated for so long. Go home with love &amp;amp; in peace. Remember this day forever!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-06 21:17:24</td>\n",
       "      <td>0</td>\n",
       "      <td>1346928882595885056</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>https://t.co/Pm2PKV0Fp3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-06 20:13:26</td>\n",
       "      <td>730357</td>\n",
       "      <td>1346912780700577792</td>\n",
       "      <td>False</td>\n",
       "      <td>156100</td>\n",
       "      <td>I am asking for everyone at the U.S. Capitol to remain peaceful. No violence! Remember, WE are the Party of Law &amp;amp; Order – respect the Law and our great men and women in Blue. Thank you!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-06 19:38:58</td>\n",
       "      <td>582183</td>\n",
       "      <td>1346904110969315328</td>\n",
       "      <td>False</td>\n",
       "      <td>107460</td>\n",
       "      <td>Please support our Capitol Police and Law Enforcement. They are truly on the side of our Country. Stay peaceful!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-06 19:24:22</td>\n",
       "      <td>0</td>\n",
       "      <td>1346900434540240896</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>Mike Pence didn’t have the courage to do what should have been done to protect our Country and our Constitution, giving States a chance to certify a corrected set of facts, not the fraudulent or inaccurate ones which they were asked to previously certify. USA demands the truth!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date  favorites                   id  isRetweet  retweets  \\\n",
       "0 2021-01-06 23:01:04          0  1346954970910707712      False         0   \n",
       "1 2021-01-06 21:17:24          0  1346928882595885056      False         0   \n",
       "2 2021-01-06 20:13:26     730357  1346912780700577792      False    156100   \n",
       "3 2021-01-06 19:38:58     582183  1346904110969315328      False    107460   \n",
       "4 2021-01-06 19:24:22          0  1346900434540240896      False         0   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                     text  \n",
       "0       These are the things and events that happen when a sacred landslide election victory is so unceremoniously &amp; viciously stripped away from great patriots who have been badly &amp; unfairly treated for so long. Go home with love &amp; in peace. Remember this day forever!  \n",
       "1                                                                                                                                                                                                                                                                 https://t.co/Pm2PKV0Fp3  \n",
       "2                                                                                           I am asking for everyone at the U.S. Capitol to remain peaceful. No violence! Remember, WE are the Party of Law &amp; Order – respect the Law and our great men and women in Blue. Thank you!  \n",
       "3                                                                                                                                                                        Please support our Capitol Police and Law Enforcement. They are truly on the side of our Country. Stay peaceful!  \n",
       "4  Mike Pence didn’t have the courage to do what should have been done to protect our Country and our Constitution, giving States a chance to certify a corrected set of facts, not the fraudulent or inaccurate ones which they were asked to previously certify. USA demands the truth!  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c50fea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove  null values\n",
    "df = df.loc[df.text.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e3be80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_clean(original):\n",
    "    word = original.lower()\n",
    "    word = unicodedata.normalize('NFKD', word)\\\n",
    "                                .encode('ascii', 'ignore')\\\n",
    "                                .decode('utf-8', 'ignore')\n",
    "    word = re.sub(r\"[^a-z0-9'\\s]\", '', word)\n",
    "    word = word.replace('\\n',' ')\n",
    "    word = word.replace('\\t',' ')\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3b7ec28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(original, extra_words=[], exclude_words=[]):\n",
    "    stopword_list = stopwords.words('english')\n",
    "\n",
    "    for word in extra_words:\n",
    "        stopword_list.append(word)\n",
    "    for word in exclude_words:\n",
    "        stopword_list.remove(word)\n",
    "\n",
    "    words = original.split()\n",
    "    filtered_words = [w for w in words if w not in stopword_list]\n",
    "\n",
    "    original_nostop = ' '.join(filtered_words)\n",
    "\n",
    "    return original_nostop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b70b16bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(original):\n",
    "    ps = nltk.porter.PorterStemmer()\n",
    "    stems = [ps.stem(word) for word in original.split()]\n",
    "    original_stemmed = ' '.join(stems)\n",
    "    return original_stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "007aea19",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []\n",
    "for sentence in df.text:\n",
    "    words = word_tokenize(stem(remove_stopwords(basic_clean(sentence))))\n",
    "    docs.append(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04fd7463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In stage 0: transferred 835 clusters with 15 clusters populated\n",
      "In stage 1: transferred 590 clusters with 15 clusters populated\n",
      "In stage 2: transferred 363 clusters with 11 clusters populated\n",
      "In stage 3: transferred 295 clusters with 10 clusters populated\n",
      "In stage 4: transferred 231 clusters with 8 clusters populated\n",
      "In stage 5: transferred 242 clusters with 7 clusters populated\n",
      "In stage 6: transferred 196 clusters with 7 clusters populated\n",
      "In stage 7: transferred 177 clusters with 7 clusters populated\n",
      "In stage 8: transferred 186 clusters with 7 clusters populated\n",
      "In stage 9: transferred 180 clusters with 7 clusters populated\n",
      "In stage 10: transferred 181 clusters with 7 clusters populated\n",
      "In stage 11: transferred 196 clusters with 7 clusters populated\n",
      "In stage 12: transferred 186 clusters with 6 clusters populated\n",
      "In stage 13: transferred 193 clusters with 5 clusters populated\n",
      "In stage 14: transferred 195 clusters with 5 clusters populated\n",
      "In stage 15: transferred 205 clusters with 7 clusters populated\n",
      "In stage 16: transferred 191 clusters with 7 clusters populated\n",
      "In stage 17: transferred 210 clusters with 7 clusters populated\n",
      "In stage 18: transferred 197 clusters with 6 clusters populated\n",
      "In stage 19: transferred 208 clusters with 6 clusters populated\n",
      "In stage 20: transferred 200 clusters with 6 clusters populated\n",
      "In stage 21: transferred 205 clusters with 5 clusters populated\n",
      "In stage 22: transferred 186 clusters with 5 clusters populated\n",
      "In stage 23: transferred 196 clusters with 5 clusters populated\n",
      "In stage 24: transferred 198 clusters with 8 clusters populated\n",
      "In stage 25: transferred 217 clusters with 7 clusters populated\n",
      "In stage 26: transferred 198 clusters with 7 clusters populated\n",
      "In stage 27: transferred 221 clusters with 6 clusters populated\n",
      "In stage 28: transferred 219 clusters with 7 clusters populated\n",
      "In stage 29: transferred 207 clusters with 7 clusters populated\n"
     ]
    }
   ],
   "source": [
    "mgp = MovieGroupProcess(K=15, alpha=0.1, beta=1, n_iters=30)\n",
    "\n",
    "vocab = set(x for doc in docs for x in doc)\n",
    "n_terms = len(vocab)\n",
    "\n",
    "y = mgp.fit(docs, n_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64ee95f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents per topic : [239   0   1   0   0  45   0   0 606  22   1   0   0   0  18]\n"
     ]
    }
   ],
   "source": [
    "doc_count = np.array(mgp.cluster_doc_count)\n",
    "print('Number of documents per topic :', doc_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c47968f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most important clusters (by number of docs inside): [ 8  0  5  9 14 10  2 13 12 11  7  6  4  3  1]\n"
     ]
    }
   ],
   "source": [
    "top_index = doc_count.argsort()[-15:][::-1]\n",
    "print('Most important clusters (by number of docs inside):', top_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c9360b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_words(cluster_word_distribution, top_cluster, values):\n",
    "    for cluster in top_cluster:\n",
    "        sort_dicts =sorted(mgp.cluster_word_distribution[cluster].items(), key=lambda k: k[1], reverse=True)[:values]\n",
    "        print('Cluster %s : %s'%(cluster,sort_dicts))\n",
    "        print('-'*120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4a7e8a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 8 : [('elect', 215), ('vote', 191), ('state', 129), ('georgia', 85), ('amp', 77), ('ballot', 75), ('republican', 72)]\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Cluster 0 : [('vaccin', 39), ('great', 38), ('thank', 33), ('get', 26), ('news', 19), ('peopl', 17), ('trump', 15)]\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Cluster 5 : [('nation', 20), ('section', 13), ('230', 13), ('amp', 12), ('defens', 11), ('termin', 10), ('secur', 9)]\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Cluster 9 : [('peopl', 8), ('antifa', 6), ('attack', 6), ('dc', 5), ('back', 4), ('polic', 4), ('left', 4)]\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Cluster 14 : [('need', 3), ('today', 3), ('recogn', 3), ('hear', 2), ('republican', 2), ('senat', 2), ('import', 2)]\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Cluster 10 : [('httpstconcauwdm8sb', 1)]\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Cluster 2 : [(\"'\", 2), ('nevada', 1), (\"'fraud\", 1), ('1500', 1), ('dead', 1), ('voter', 1), ('42248', 1)]\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Cluster 13 : []\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Cluster 12 : []\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Cluster 11 : []\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Cluster 7 : []\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Cluster 6 : []\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Cluster 4 : []\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Cluster 3 : []\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Cluster 1 : []\n",
      "------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Show the top 7 words in term frequency for each cluster \n",
    "top_words(mgp.cluster_word_distribution, top_index, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6b5ed4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_dict = {}\n",
    "topic_names = ['Topic #1',\n",
    "               'Topic #2',\n",
    "               'Topic #3',\n",
    "               'Topic #4',\n",
    "               'Topic #5',\n",
    "               'Topic #6',\n",
    "               'Topic #7',\n",
    "               'Topic #8',\n",
    "               'Topic #9',\n",
    "               'Topic #10',\n",
    "               'Topic #11',\n",
    "               'Topic #12',\n",
    "               'Topic #13',\n",
    "               'Topic #14',\n",
    "               'Topic #15'\n",
    "              ]\n",
    "for i, topic_num in enumerate(top_index):\n",
    "    topic_dict[topic_num]=topic_names[i] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "723bae58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_topics_dataframe(data_text=df.text,  mgp=mgp, threshold=0.3, topic_dict=topic_dict, stem_text=docs):\n",
    "    result = pd.DataFrame(columns=['text', 'topic', 'stems'])\n",
    "    for i, text in enumerate(data_text):\n",
    "        result.at[i, 'text'] = text\n",
    "        result.at[i, 'stems'] = stem_text[i]\n",
    "        prob = mgp.choose_best_label(stem_text[i])\n",
    "        if prob[1] >= threshold:\n",
    "            result.at[i, 'topic'] = topic_dict[prob[0]]\n",
    "        else:\n",
    "            result.at[i, 'topic'] = 'Other'\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ab8e795",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfx = create_topics_dataframe(data_text=df.text,  mgp=mgp, threshold=0.3, topic_dict=topic_dict, stem_text=docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d79ebb9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>topic</th>\n",
       "      <th>stems</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>These are the things and events that happen when a sacred landslide election victory is so unceremoniously &amp;amp; viciously stripped away from great patriots who have been badly &amp;amp; unfairly treated for so long. Go home with love &amp;amp; in peace. Remember this day forever!</td>\n",
       "      <td>Topic #1</td>\n",
       "      <td>[thing, event, happen, sacr, landslid, elect, victori, unceremoni, amp, vicious, strip, away, great, patriot, badli, amp, unfairli, treat, long, go, home, love, amp, peac, rememb, day, forev]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://t.co/Pm2PKV0Fp3</td>\n",
       "      <td>Topic #2</td>\n",
       "      <td>[httpstcopm2pkv0fp3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am asking for everyone at the U.S. Capitol to remain peaceful. No violence! Remember, WE are the Party of Law &amp;amp; Order – respect the Law and our great men and women in Blue. Thank you!</td>\n",
       "      <td>Topic #1</td>\n",
       "      <td>[ask, everyon, us, capitol, remain, peac, violenc, rememb, parti, law, amp, order, respect, law, great, men, women, blue, thank]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Please support our Capitol Police and Law Enforcement. They are truly on the side of our Country. Stay peaceful!</td>\n",
       "      <td>Topic #4</td>\n",
       "      <td>[pleas, support, capitol, polic, law, enforc, truli, side, countri, stay, peac]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mike Pence didn’t have the courage to do what should have been done to protect our Country and our Constitution, giving States a chance to certify a corrected set of facts, not the fraudulent or inaccurate ones which they were asked to previously certify. USA demands the truth!</td>\n",
       "      <td>Topic #1</td>\n",
       "      <td>[mike, penc, didnt, courag, done, protect, countri, constitut, give, state, chanc, certifi, correct, set, fact, fraudul, inaccur, one, ask, previous, certifi, usa, demand, truth]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                     text  \\\n",
       "0       These are the things and events that happen when a sacred landslide election victory is so unceremoniously &amp; viciously stripped away from great patriots who have been badly &amp; unfairly treated for so long. Go home with love &amp; in peace. Remember this day forever!   \n",
       "1                                                                                                                                                                                                                                                                 https://t.co/Pm2PKV0Fp3   \n",
       "2                                                                                           I am asking for everyone at the U.S. Capitol to remain peaceful. No violence! Remember, WE are the Party of Law &amp; Order – respect the Law and our great men and women in Blue. Thank you!   \n",
       "3                                                                                                                                                                        Please support our Capitol Police and Law Enforcement. They are truly on the side of our Country. Stay peaceful!   \n",
       "4  Mike Pence didn’t have the courage to do what should have been done to protect our Country and our Constitution, giving States a chance to certify a corrected set of facts, not the fraudulent or inaccurate ones which they were asked to previously certify. USA demands the truth!   \n",
       "\n",
       "      topic  \\\n",
       "0  Topic #1   \n",
       "1  Topic #2   \n",
       "2  Topic #1   \n",
       "3  Topic #4   \n",
       "4  Topic #1   \n",
       "\n",
       "                                                                                                                                                                                             stems  \n",
       "0  [thing, event, happen, sacr, landslid, elect, victori, unceremoni, amp, vicious, strip, away, great, patriot, badli, amp, unfairli, treat, long, go, home, love, amp, peac, rememb, day, forev]  \n",
       "1                                                                                                                                                                             [httpstcopm2pkv0fp3]  \n",
       "2                                                                 [ask, everyon, us, capitol, remain, peac, violenc, rememb, parti, law, amp, order, respect, law, great, men, women, blue, thank]  \n",
       "3                                                                                                                  [pleas, support, capitol, polic, law, enforc, truli, side, countri, stay, peac]  \n",
       "4               [mike, penc, didnt, courag, done, protect, countri, constitut, give, state, chanc, certifi, correct, set, fact, fraudul, inaccur, one, ask, previous, certifi, usa, demand, truth]  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "43a98a3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Topic #1    648\n",
       "Topic #2    238\n",
       "Topic #3     26\n",
       "Topic #4     10\n",
       "Topic #5      9\n",
       "Topic #7      1\n",
       "Name: topic, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfx.topic.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "992c23bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfx.to_csv('../data/out/trump_archive_with_topics.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
